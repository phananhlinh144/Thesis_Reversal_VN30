import streamlit as st
import pandas as pd
import numpy as np
import tensorflow as tf
import joblib
import pandas_ta as ta
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime
from vnstock import Vnstock
import time
import requests
from io import BytesIO

# --- 1. C·∫§U H√åNH H·ªÜ TH·ªêNG ---
st.set_page_config(page_title="VN30 AI Ensemble Pro", layout="wide", page_icon="üíé")

if 'scan_results' not in st.session_state:
    st.session_state.scan_results = None

@st.cache_resource
def load_assets():
    try:
        m50 = tf.keras.models.load_model('Full_K10_Win50_Hybrid.keras')
        m10 = tf.keras.models.load_model('Baseline_K10_Win10_Hybrid.keras')
        bundle = joblib.load('smart_scaler_system.pkl')
        return m50, m10, bundle
    except:
        st.error("‚ùå Kh√¥ng t√¨m th·∫•y file Model ho·∫∑c Scaler. Ki·ªÉm tra l·∫°i th∆∞ m·ª•c!")
        return None, None, None

m50, m10, bundle = load_assets()
vn30_symbols = ['ACB', 'BCM', 'BID', 'CTG', 'DGC', 'FPT', 'GAS', 'GVR', 'HDB', 'HPG', 'LPB', 'MSN', 'MBB', 'MWG', 'PLX', 'SAB', 'SHB', 'SSB', 'SSI', 'STB', 'TCB', 'TPB', 'VCB', 'VIC', 'VHM', 'VIB', 'VJC', 'VNM', 'VPB', 'VRE']
LABELS = {0: 'MUA üü¢', 1: 'HOLD üü°', 2: 'B√ÅN üî¥'}

# --- 2. LOGIC ENSEMBLE ---
def get_ensemble_signal(p50, p10):
    r50 = np.argmax(p50)
    r10 = np.argmax(p10)
    # K·∫øt h·ª£p: ∆Øu ti√™n d√†i h·∫°n r50, ng·∫Øn h·∫°n r10 l√†m b·ªô l·ªçc
    if r50 == 0 and r10 == 0: return "MUA M·∫†NH üíé", "Mua"
    if r50 == 0: return "MUA (ƒê·ª£i ƒëi·ªÉm v√†o) üü¢", "Mua"
    if r50 == 2: return "B√ÅN üî¥", "B√°n"
    if r10 == 2: return "C·∫®N TR·ªåNG üü°", "Ngang"
    return "THEO D√ïI ‚ö™", "Ngang"

# --- 3. X·ª¨ L√ù D·ªÆ LI·ªÜU ---
@st.cache_data(ttl=3600)
def get_data(symbol):
    try:
        # T·∫£i t·ª´ Drive (D·ªØ li·ªáu l·ªãch s·ª≠)
        file_id = '1xG6J9fBEF_Z4KY3x_frUwnhVTSA6HG2r'
        url = f'https://drive.google.com/uc?export=download&id={file_id}'
        resp = requests.get(url, timeout=10)
        df_off = pd.read_csv(BytesIO(resp.content), on_bad_lines='skip', engine='python')
        col = next((c for c in df_off.columns if c.lower() in ['symbol', 'ticker', 'm√£']), None)
        df_stock = df_off[df_off[col] == symbol].copy()
        df_stock['Date'] = pd.to_datetime(df_stock['Date'], errors='coerce')

        # T·∫£i Online (C·∫≠p nh·∫≠t phi√™n m·ªõi nh·∫•t 2026)
        client = Vnstock()
        df_on = client.stock(symbol=symbol).quote.history(start="2025-01-01", end=datetime.now().strftime('%Y-%m-%d'))
        if not df_on.empty:
            df_on = df_on.rename(columns={'time':'Date','open':'Open','high':'High','low':'Low','close':'Close','volume':'Volume'})
            df_on['Date'] = pd.to_datetime(df_on['Date'])
            df_full = pd.concat([df_stock, df_on], ignore_index=True).drop_duplicates(subset=['Date']).sort_values('Date')
            return df_full
        return df_stock
    except: return pd.DataFrame()

def build_feats(df):
    if df.empty or len(df) < 55: return pd.DataFrame()
    df = df.copy().reset_index(drop=True)
    df['RSI'] = ta.rsi(df['Close'], length=14)
    for n in [1, 5, 10, 20]: df[f'RC_{n}'] = df['Close'].pct_change(n) * 100
    for col in bundle['global_scaler'].feature_names_in_:
        if col not in df.columns: df[col] = 0.0
    return df.dropna(subset=['RSI']).tail(65)

def run_pred(df, symbol):
    try:
        sc = bundle['local_scalers_dict'].get(symbol, bundle['global_scaler'])
        feats = bundle['global_scaler'].feature_names_in_
        window = df.iloc[-50:][feats]
        scaled = sc.transform(window)
        p50 = m50.predict(np.expand_dims(scaled, 0), verbose=0)[0]
        p10 = m10.predict(np.expand_dims(scaled[-10:, :17], 0), verbose=0)[0]
        return p50, p10
    except: return None, None

# --- 4. GIAO DI·ªÜN CH√çNH ---
tab_scan, tab_detail = st.tabs(["üìã B·∫£ng T·ªïng H·ª£p VN30", "üîç Soi Chi Ti·∫øt & K·ªπ Thu·∫≠t"])

with tab_scan:
    st.header("‚ö° Qu√©t & Ph√¢n nh√≥m Ensemble")
    if st.button("üöÄ B·∫Øt ƒë·∫ßu qu√©t th·ªã tr∆∞·ªùng"):
        results = []
        bar = st.progress(0)
        for i, sym in enumerate(vn30_symbols):
            df = get_data(sym)
            df_p = build_feats(df)
            if not df_p.empty:
                p50, p10 = run_pred(df_p, sym)
                if p50 is not None:
                    ens_text, ens_group = get_ensemble_signal(p50, p10)
                    results.append({
                        "M√£": sym, "Gi√° HT": df_p.iloc[-1]['Close'],
                        "D√†i h·∫°n": LABELS[np.argmax(p50)], "Ng·∫Øn h·∫°n": LABELS[np.argmax(p10)],
                        "Ensemble": ens_text, "Nh√≥m": ens_group
                    })
            bar.progress((i + 1) / len(vn30_symbols))
        st.session_state.scan_results = pd.DataFrame(results)

    if st.session_state.scan_results is not None:
        df_res = st.session_state.scan_results
        c_mua, c_ngang, c_ban = st.columns(3)
        with c_mua:
            st.success("üü¢ DANH M·ª§C MUA")
            st.dataframe(df_res[df_res['Nh√≥m'] == "Mua"][['M√£', 'Gi√° HT', 'Ensemble']], use_container_width=True, hide_index=True)
        with c_ngang:
            st.warning("üü° THEO D√ïI")
            st.dataframe(df_res[df_res['Nh√≥m'] == "Ngang"][['M√£', 'Gi√° HT', 'Ensemble']], use_container_width=True, hide_index=True)
        with c_ban:
            st.error("üî¥ DANH M·ª§C B√ÅN")
            st.dataframe(df_res[df_res['Nh√≥m'] == "B√°n"][['M√£', 'Gi√° HT', 'Ensemble']], use_container_width=True, hide_index=True)

with tab_detail:
    sel_sym = st.selectbox("Ch·ªçn m√£ ch·ª©ng kho√°n", vn30_symbols)
    if st.button(f"üîç Ph√¢n t√≠ch s√¢u {sel_sym}"):
        df = get_data(sel_sym)
        df_p = build_feats(df)
        if not df_p.empty:
            p50, p10 = run_pred(df_p, sel_sym)
            if p50 is not None:
                ens_text, _ = get_ensemble_signal(p50, p10)
                
                # T√≠nh Bollinger Bands
                bb = ta.bbands(df_p['Close'], length=20, std=2)
                df_plot = pd.concat([df_p, bb], axis=1).tail(60)

                # V·∫Ω Bi·ªÉu ƒë·ªì 3 t·∫ßng
                fig = make_subplots(rows=3, cols=1, shared_xaxes=True, vertical_spacing=0.05, row_heights=[0.5, 0.2, 0.3])
                # T·∫ßng 1: Candle + BB
                fig.add_trace(go.Candlestick(x=df_plot['Date'], open=df_plot['Open'], high=df_plot['High'], low=df_plot['Low'], close=df_plot['Close'], name='Gi√°'), row=1, col=1)
                fig.add_trace(go.Scatter(x=df_plot['Date'], y=df_plot['BBU_20_2.0'], line=dict(color='rgba(173, 216, 230, 0.4)'), name='BB Upper'), row=1, col=1)
                fig.add_trace(go.Scatter(x=df_plot['Date'], y=df_plot['BBL_20_2.0'], line=dict(color='rgba(173, 216, 230, 0.4)'), fill='tonexty', name='BB Lower'), row=1, col=1)
                
                # M≈©i t√™n d·ª± b√°o
                arrow_c = "green" if "MUA" in ens_text else ("red" if "B√ÅN" in ens_text else "gray")
                fig.add_annotation(x=df_plot['Date'].iloc[-1], y=df_plot['Close'].iloc[-1], text=f"AI: {ens_text}", showarrow=True, arrowhead=2, arrowcolor=arrow_c, ay=-50 if "MUA" in ens_text else 50)

                # T·∫ßng 2: RSI
                fig.add_trace(go.Scatter(x=df_plot['Date'], y=df_plot['RSI'], line=dict(color='purple'), name='RSI'), row=2, col=1)
                fig.add_hline(y=70, line_dash="dot", line_color="red", row=2, col=1)
                fig.add_hline(y=30, line_dash="dot", line_color="green", row=2, col=1)

                # T·∫ßng 3: Volume
                fig.add_trace(go.Bar(x=df_plot['Date'], y=df_plot['Volume'], name='Volume', marker_color='orange'), row=3, col=1)

                fig.update_layout(height=800, template='plotly_dark', xaxis_rangeslider_visible=False)
                st.plotly_chart(fig, use_container_width=True)
        else:
            st.error("D·ªØ li·ªáu kh√¥ng ƒë·ªß ƒë·ªÉ ph√¢n t√≠ch.")
