import streamlit as st
import pandas as pd
import numpy as np
import tensorflow as tf
import joblib
import pandas_ta as ta
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
from vnstock import Vnstock
import time
import requests
from io import BytesIO

# --- 1. C·∫§U H√åNH & TR·∫†NG TH√ÅI ---
st.set_page_config(page_title="VN30 AI Hybrid Pro", layout="wide", page_icon="üíé")

if 'scan_results' not in st.session_state:
    st.session_state.scan_results = None

@st.cache_resource
def load_assets():
    try:
        m50 = tf.keras.models.load_model('Full_K10_Win50_Hybrid.keras')
        m10 = tf.keras.models.load_model('Baseline_K10_Win10_Hybrid.keras')
        bundle = joblib.load('smart_scaler_system.pkl')
        return m50, m10, bundle
    except:
        return None, None, None

m50, m10, bundle = load_assets()
vn30_symbols = ['ACB', 'BCM', 'BID', 'CTG', 'DGC', 'FPT', 'GAS', 'GVR', 'HDB', 'HPG', 'LPB', 'MSN', 'MBB', 'MWG', 'PLX', 'SAB', 'SHB', 'SSB', 'SSI', 'STB', 'TCB', 'TPB', 'VCB', 'VIC', 'VHM', 'VIB', 'VJC', 'VNM', 'VPB', 'VRE']
LABELS = {0: 'MUA üü¢', 1: 'HOLD üü°', 2: 'B√ÅN üî¥'}

# --- 2. H√ÄM T·∫¢I DATA (FIX TRI·ªÜT ƒê·ªÇ L·ªñI DRIVE) ---
@st.cache_data(ttl=3600)
def get_hybrid_data(symbol):
    try:
        # S·ª≠ d·ª•ng link download tr·ª±c ti·∫øp ƒë·ªÉ tr√°nh l·ªói Tokenizing
        file_id = '1xG6J9fBEF_Z4KY3x_frUwnhVTSA6HG2r'
        csv_url = f'https://drive.google.com/uc?export=download&id={file_id}'
        
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(csv_url, headers=headers)
        
        if response.status_code == 200:
            df_offline = pd.read_csv(BytesIO(response.content), on_bad_lines='skip', engine='python')
            col_name = next((c for c in df_offline.columns if c.lower() in ['symbol', 'ticker', 'm√£']), None)
            df_stock = df_offline[df_offline[col_name] == symbol].copy()
            df_stock['Date'] = pd.to_datetime(df_stock['Date'], errors='coerce')
        else:
            df_stock = pd.DataFrame()

        # L·∫•y th√™m d·ªØ li·ªáu t·ª´ Vnstock ƒë·ªÉ b√π v√†o
        client = Vnstock()
        # L·∫•y kho·∫£ng 100 phi√™n g·∫ßn nh·∫•t ƒë·ªÉ ƒë·∫£m b·∫£o ƒë·ªß d·ªØ li·ªáu t√≠nh to√°n
        df_online = client.stock(symbol=symbol).quote.history(start="2025-01-01", end=datetime.now().strftime('%Y-%m-%d'))
        
        if not df_online.empty:
            df_online = df_online.rename(columns={'time':'Date','open':'Open','high':'High','low':'Low','close':'Close','volume':'Volume'})
            df_online['Date'] = pd.to_datetime(df_online['Date'])
            df_full = pd.concat([df_stock, df_online], ignore_index=True)
            df_full = df_full.drop_duplicates(subset=['Date']).sort_values('Date')
            return df_full
        
        return df_stock
    except:
        return pd.DataFrame()

# --- 3. H√ÄM T√çNH TO√ÅN (GI·ªÆ NGUY√äN NH∆ØNG TH√äM CHECK) ---
def build_features(df):
    if df.empty or len(df) < 55: return pd.DataFrame()
    try:
        df = df.copy().reset_index(drop=True)
        # T√≠nh to√°n c√°c ch·ªâ b√°o (RSI, RC...)
        df['RSI'] = ta.rsi(df['Close'], length=14)
        for n in [1, 5, 10, 20]:
            df[f'RC_{n}'] = df['Close'].pct_change(n) * 100
        # Th√™m c√°c c·ªôt ·∫£o n·∫øu thi·∫øu ƒë·ªÉ scaler kh√¥ng l·ªói
        for col in bundle['global_scaler'].feature_names_in_:
            if col not in df.columns: df[col] = 0.0
            
        return df.dropna(subset=['RSI']).tail(60) # Gi·ªØ l·∫°i ƒë·ªß ƒë·ªÉ d·ª± b√°o
    except: return pd.DataFrame()

# --- 4. GIAO DI·ªÜN ---
tab_scan, tab_detail = st.tabs(["üìä B·∫£ng T·ªïng H·ª£p VN30", "üîç Soi Chi Ti·∫øt & Backtest"])

with tab_scan:
    if st.button("üöÄ B·∫Øt ƒë·∫ßu qu√©t th·ªã tr∆∞·ªùng"):
        results = []
        progress = st.progress(0)
        status = st.empty()
        
        for i, sym in enumerate(vn30_symbols):
            status.text(f"‚è≥ ƒêang qu√©t {sym}...")
            df = get_hybrid_data(sym)
            df_p = build_features(df)
            
            if not df_p.empty:
                p50, p10 = run_prediction(df_p, sym)
                if p50 is not None:
                    r50, r10 = np.argmax(p50), np.argmax(p10)
                    results.append({
                        "M√£": sym, "Gi√°": f"{df_p.iloc[-1]['Close']:,}",
                        "D√†i h·∫°n": LABELS[r50], "Ng·∫Øn h·∫°n": LABELS[r10],
                        "Tin c·∫≠y": f"{np.max(p50):.1%}"
                    })
            progress.progress((i + 1) / len(vn30_symbols))
        
        st.session_state.scan_results = pd.DataFrame(results)
        status.success("‚úÖ ƒê√£ ho√†n t·∫•t!")

    if st.session_state.scan_results is not None:
        st.table(st.session_state.scan_results)

with tab_detail:
    sel_sym = st.selectbox("Ch·ªçn m√£ ch·ª©ng kho√°n", vn30_symbols)
    if st.button(f"üîç Ph√¢n t√≠ch chi ti·∫øt {sel_sym}"):
        df = get_hybrid_data(sel_sym)
        df_p = build_features(df)
        if len(df_p) >= 50:
            # Hi·ªán chart v√† d·ª± b√°o ·ªü ƒë√¢y (d√πng code c≈© c·ªßa b·∫°n)
            st.success(f"D·ªØ li·ªáu {sel_sym} OK: {len(df_p)} phi√™n.")
        else:
            st.error(f"D·ªØ li·ªáu {sel_sym} v·∫´n kh√¥ng ƒë·ªß (Ch·ªâ c√≥ {len(df)} phi√™n). Ki·ªÉm tra l·∫°i file CSV.")
