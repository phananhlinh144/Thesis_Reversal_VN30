import pandas as pd
import numpy as np
import tensorflow as tf
import joblib
import pandas_ta as ta
import time
import warnings
import os
from datetime import datetime, timedelta
from vnstock import * # S·ª≠ d·ª•ng vnstock phi√™n b·∫£n c≈©

# T·∫Øt c√°c c·∫£nh b√°o ƒë·ªÉ log s·∫°ch s·∫Ω
warnings.filterwarnings('ignore')
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

# --- 1. C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N ---
MODEL_WIN50_PATH = 'Full_K10_Win50_Hybrid.keras'
MODEL_WIN10_PATH = 'Baseline_K10_Win10_Hybrid.keras'
SCALER_PATH      = 'smart_scaler_system.pkl'
HISTORY_CSV_PATH = 'vn30_data_raw.csv' 

FEATS_FULL = [
    'RC_1', 'RC_2', 'RC_3', 'RC_5', 'RC_8', 'RC_13', 'RC_21', 'RC_34', 'RC_55',
    'Grad_5', 'Grad_10', 'Grad_20', 'RSI', 'BB_PctB', 'MACD_Hist', 'Vol_Ratio', 'ATR_Rel', 'Dist_Prev_K10'
]

# --- 2. LOAD MODELS ---
print("‚è≥ ƒêang kh·ªüi t·∫°o h·ªá th·ªëng AI...")
try:
    model_win50 = tf.keras.models.load_model(MODEL_WIN50_PATH)
    model_win10 = tf.keras.models.load_model(MODEL_WIN10_PATH)
    scaler_bundle = joblib.load(SCALER_PATH)
    local_scalers = scaler_bundle['local_scalers_dict']
    global_scaler = scaler_bundle['global_scaler']
    print("‚úÖ Load Model th√†nh c√¥ng.")
except Exception as e:
    print(f"‚ùå L·ªói Load Model: {e}")
    exit()

# --- 3. H√ÄM X·ª¨ L√ù D·ªÆ LI·ªÜU ---

def get_hybrid_data(symbol):
    """ƒê·ªçc d·ªØ li·ªáu t·ª´ file csv (ƒë·∫øn 10/1) v√† n·ªëi th√™m t·ª´ VCI b·∫±ng vnstock c≈©"""
    try:
        # 1. ƒê·ªçc d·ªØ li·ªáu l·ªãch s·ª≠ t·ª´ file csv (D·ªØ li·ªáu b·∫°n ƒë√£ g·ª≠i)
        full_hist = pd.read_csv(HISTORY_CSV_PATH)
        full_hist['Date'] = pd.to_datetime(full_hist['Date'])
        df_old = full_hist[full_hist['Symbol'] == symbol].sort_values('Date')
        
        # 2. L·∫•y d·ªØ li·ªáu m·ªõi t·ª´ ngu·ªìn VCI (vnstock c≈© d√πng h√†m stock_historical_data)
        start_date = "2026-01-11"
        end_date = datetime.now().strftime('%Y-%m-%d')
        
        try:
            # L∆∞u √Ω: vnstock c≈© l·∫•y d·ªØ li·ªáu theo ƒë·ªãnh d·∫°ng 'YYYY-MM-DD'
            df_new = stock_historical_data(symbol=symbol, 
                                           start_date=start_date, 
                                           end_date=end_date, 
                                           resolution='1D', 
                                           type='stock', 
                                           source='VCI')
            
            if df_new is not None and not df_new.empty:
                # Chu·∫©n h√≥a t√™n c·ªôt vnstock c≈© v·ªÅ d·∫°ng chung
                df_new = df_new.rename(columns={'time':'Date','open':'Open','high':'High','low':'Low','close':'Close','volume':'Volume'})
                df_new['Date'] = pd.to_datetime(df_new['Date'])
                df_final = pd.concat([df_old, df_new], ignore_index=True)
            else:
                df_final = df_old
        except:
            df_final = df_old

        df_final = df_final.drop_duplicates(subset=['Date']).sort_values('Date').reset_index(drop=True)
        
        # √âp ki·ªÉu d·ªØ li·ªáu s·ªë ƒë·ªÉ tr√°nh l·ªói t√≠nh to√°n indicators
        for col in ['Open', 'High', 'Low', 'Close', 'Volume']:
            df_final[col] = pd.to_numeric(df_final[col], errors='coerce')
            
        return df_final
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói x·ª≠ l√Ω {symbol}: {e}")
        return pd.DataFrame()

def compute_features(df):
    if len(df) < 60: return pd.DataFrame()
    g = df.copy()
    g = g.ffill().bfill()
    
    # T√≠nh to√°n Returns Change
    for n in [1, 2, 3, 5, 8, 13, 21, 34, 55]: 
        g[f'RC_{n}'] = g['Close'].pct_change(n) * 100
        
    # T√≠nh to√°n Gradient c·ªßa c√°c ƒë∆∞·ªùng MA
    for n in [5, 10, 20]:
        ma = g['Close'].rolling(window=n).mean().bfill()
        g[f'Grad_{n}'] = np.gradient(ma)
    
    # Ch·ªâ b√°o k·ªπ thu·∫≠t t·ª´ pandas_ta
    g['Vol_Ratio'] = g['Volume'] / ta.sma(g['Volume'], length=20)
    g['RSI'] = ta.rsi(g['Close'], length=14)
    
    bb = ta.bbands(g['Close'], length=20, std=2)
    # T√¨m c·ªôt c√≥ t√™n ch·ª©a 'B' (th∆∞·ªùng l√† BBP_20_2.0)
    pctb_col = [c for c in bb.columns if c.startswith('BBP')]
    if pctb_col:
        g['BB_PctB'] = bb[pctb_col[0]]
    else:
        g['BB_PctB'] = bb.iloc[:, 4] # Quay l·∫°i c√°ch c≈© n·∫øu kh√¥ng t√¨m th·∫•y
    
    g['MACD_Hist'] = ta.macd(g['Close']).iloc[:, 1]
    g['ATR_Rel'] = ta.atr(g['High'], g['Low'], g['Close'], length=14) / g['Close']
    
    # Kho·∫£ng c√°ch so v·ªõi n·∫øn K10 tr∆∞·ªõc ƒë√≥
    ma20 = g['Close'].rolling(20).mean()
    g['Dist_Prev_K10'] = 0.0
    g.loc[g['Close'] >= ma20, 'Dist_Prev_K10'] = (g['Close'] - g['Close'].rolling(20).min()) / g['Close'].rolling(20).min()
    g.loc[g['Close'] < ma20, 'Dist_Prev_K10'] = (g['Close'] - g['Close'].rolling(20).max()) / g['Close'].rolling(20).max()

    g = g.dropna()
    
    if len(g) < 55:
        print(f"‚ö†Ô∏è C·∫£nh b√°o: D·ªØ li·ªáu sau khi t√≠nh to√°n qu√° √≠t d√≤ng.")
    return g.reset_index(drop=True)

def predict_at_index(df_feat, symbol, idx=-1):
    actual_idx = len(df_feat) + idx if idx < 0 else idx
    if actual_idx < 50: return None

    # Slice c·ª≠a s·ªï 50 phi√™n v√† 10 phi√™n
    d50 = df_feat.iloc[actual_idx-49 : actual_idx+1]
    d10 = df_feat.iloc[actual_idx-9 : actual_idx+1]

    # Scaling d·ªØ li·ªáu
    scaler = local_scalers.get(symbol, global_scaler)
    s50 = scaler.transform(d50[FEATS_FULL].values)
    s10 = scaler.transform(d10[FEATS_FULL].values)

    # D·ª± b√°o t·ª´ 2 model Hybrid
    p50_raw = model_win50.predict(np.expand_dims(s50, 0), verbose=0)[0]
    p10_raw = model_win10.predict(np.expand_dims(s10[:, :17], 0), verbose=0)[0]

    c50, c10 = np.argmax(p50_raw), np.argmax(p10_raw)
    
    signal = "THEO D√ïI"
    if c50 == 0 and c10 == 0: signal = "MUA"
    elif c50 == 2 and c10 == 2: signal = "B√ÅN"
    
    labels = {0: 'TƒÉng', 1: 'Ngang', 2: 'Gi·∫£m'}

    return {
        "M√£": symbol,
        "Ng√†y": df_feat.iloc[actual_idx]['Date'].strftime('%Y-%m-%d'),
        "Gi√°": int(df_feat.iloc[actual_idx]['Close']),
        "Win50": f"{labels[c50]} ({p50_raw[c50]:.0%})",
        "Win10": f"{labels[c10]} ({p10_raw[c10]:.0%})",
        "ENSEMBLE": signal
    }

# --- 4. CH∆Ø∆†NG TR√åNH CH√çNH ---

if __name__ == "__main__":
    vn30 = ['ACB', 'BCM', 'BID', 'CTG', 'DGC', 'FPT', 'GAS', 'GVR', 'HDB', 'HPG', 
            'LPB', 'MSN', 'MBB', 'MWG', 'PLX', 'SAB', 'SHB', 'SSB', 'SSI', 'STB', 
            'TCB', 'TPB', 'VCB', 'VIC', 'VHM', 'VIB', 'VJC', 'VNM', 'VPB', 'VRE']
    
    final_output = []
    LOOKBACK = 20 # S·ªë phi√™n l·ªãch s·ª≠ ƒë·ªÉ hi·ªÉn th·ªã tr√™n Web
    
    print(f"üöÄ B·∫Øt ƒë·∫ßu qu√©t d·ªØ li·ªáu Hybrid (vnstock c≈©)...")
    for i, sym in enumerate(vn30):
        print(f"\r‚è≥ [{i+1}/30] ƒêang x·ª≠ l√Ω: {sym:<5}", end="")
        df = get_hybrid_data(sym)
        if df.empty: continue
        
        df_feat = compute_features(df)
        if df_feat.empty: continue
        
        # L∆∞u k·∫øt qu·∫£ 20 phi√™n g·∫ßn nh·∫•t
        for j in range(-LOOKBACK, 0):
            try:
                res = predict_at_index(df_feat, sym, idx=j)
                if res: final_output.append(res)
            except: continue
            
        time.sleep(1.7) # Ngh·ªâ ƒë·ªÉ kh√¥ng b·ªã firewall ch·∫∑n IP
        
    if final_output:
        pd.DataFrame(final_output).to_csv('vn30_signals.csv', index=False, encoding='utf-8-sig')
        print(f"\n‚úÖ H·ªá th·ªëng ƒë√£ c·∫≠p nh·∫≠t vn30_signals.csv th√†nh c√¥ng!")


